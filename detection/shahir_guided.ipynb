{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic python and ML Libraries\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# for ignoring warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# We will be reading images using OpenCV\n",
    "import cv2\n",
    "\n",
    "# matplotlib for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# torchvision libraries\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms as torchtrans\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "\n",
    "# helper libraries\n",
    "from engine import train_one_epoch, evaluate\n",
    "import utils\n",
    "import transforms as T\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.models.detection as detection\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models.detection.faster_rcnn import FasterRCNN_ResNet50_FPN_Weights\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "\n",
    "# Send train=True for training transforms and False for val/test transforms\n",
    "def get_transform(train):\n",
    "    transform = [transforms.ToTensor()]\n",
    "    return transforms.Compose(transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Kitti(torchvision.datasets.Kitti):\n",
    "    def __getitem__(self, index):\n",
    "        image, target = super().__getitem__(index)\n",
    "        # Convert target format from list of dicts to the correct dict format\n",
    "        labels = [['Car', 'Van', 'Truck', 'Pedestrian', 'Person_sitting', 'Cyclist', 'Tram', 'Misc', 'DontCare'].index(t['type']) for t in target]\n",
    "        boxes = [t['bbox'] for t in target]\n",
    "        \n",
    "        target = {'boxes': torch.as_tensor(boxes, dtype=torch.float32).reshape(-1, 4), 'labels': torch.as_tensor(labels)}\n",
    "        return image, target\n",
    "\n",
    "dataset = Kitti(root='../data', transform=get_transform(train=True))\n",
    "dataset_test = Kitti(root='../data', transform=get_transform(train=False))\n",
    "\n",
    "\n",
    "# split the dataset in train and test set\n",
    "torch.manual_seed(1)\n",
    "indices = torch.randperm(len(dataset)).tolist()\n",
    "\n",
    "# train test split\n",
    "test_split = 0.2\n",
    "tsize = int(len(dataset)*test_split)\n",
    "dataset = torch.utils.data.Subset(dataset, indices[:-tsize])\n",
    "dataset_test = torch.utils.data.Subset(dataset_test, indices[-tsize:])\n",
    "\n",
    "# define training and validation data loaders\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "  dataset,\n",
    "  batch_size=4,\n",
    "  shuffle=True,\n",
    "  num_workers=0,\n",
    "  collate_fn=utils.collate_fn,\n",
    ")\n",
    "\n",
    "data_loader_test = torch.utils.data.DataLoader(\n",
    "  dataset_test,\n",
    "  batch_size=4,\n",
    "  shuffle=False,\n",
    "  num_workers=0,\n",
    "  collate_fn=utils.collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_object_detection_model(num_classes):\n",
    "  # load a model pre-trained pre-trained on COCO\n",
    "  model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "  # get number of input features for the classifier\n",
    "  in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "  # replace the pre-trained head with a new one\n",
    "  model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.2196, 0.2196, 0.2039,  ..., 0.0431, 0.0431, 0.0471],\n",
      "         [0.2196, 0.2196, 0.2157,  ..., 0.0471, 0.0471, 0.0431],\n",
      "         [0.2196, 0.2235, 0.2157,  ..., 0.0510, 0.0549, 0.0549],\n",
      "         ...,\n",
      "         [0.2902, 0.2588, 0.2549,  ..., 0.1176, 0.1255, 0.1294],\n",
      "         [0.2353, 0.2706, 0.2784,  ..., 0.1059, 0.1176, 0.1216],\n",
      "         [0.2392, 0.2980, 0.3373,  ..., 0.1059, 0.1176, 0.1216]],\n",
      "\n",
      "        [[0.3333, 0.3255, 0.3176,  ..., 0.0588, 0.0510, 0.0471],\n",
      "         [0.3294, 0.3216, 0.3137,  ..., 0.0745, 0.0588, 0.0510],\n",
      "         [0.3176, 0.3216, 0.3176,  ..., 0.0745, 0.0667, 0.0588],\n",
      "         ...,\n",
      "         [0.4157, 0.2824, 0.2510,  ..., 0.1647, 0.1725, 0.1647],\n",
      "         [0.3529, 0.2157, 0.2549,  ..., 0.1373, 0.1451, 0.1569],\n",
      "         [0.1686, 0.2392, 0.3176,  ..., 0.1176, 0.1294, 0.1451]],\n",
      "\n",
      "        [[0.4157, 0.4314, 0.4353,  ..., 0.0745, 0.0549, 0.0471],\n",
      "         [0.4118, 0.4314, 0.4431,  ..., 0.0667, 0.0588, 0.0588],\n",
      "         [0.4000, 0.4275, 0.4549,  ..., 0.0627, 0.0627, 0.0627],\n",
      "         ...,\n",
      "         [0.3020, 0.3059, 0.3961,  ..., 0.1686, 0.1608, 0.1686],\n",
      "         [0.2863, 0.3098, 0.4157,  ..., 0.1490, 0.1490, 0.1647],\n",
      "         [0.2627, 0.2549, 0.4627,  ..., 0.1176, 0.1098, 0.1373]]])\n",
      "<class 'dict'>\n",
      "{'boxes': tensor([[557.1800, 173.5500, 628.7500, 238.8100],\n",
      "        [ 32.0700,   0.0000, 520.3000, 375.0000],\n",
      "        [483.1300, 182.0800, 540.1200, 221.4100]]),\n",
      " 'labels': tensor([0, 2, 0])}\n",
      "data loader part\n",
      "4\n",
      "torch.Size([3, 375, 1242])\n",
      "<class 'tuple'>\n",
      "({'boxes': tensor([[ 334.2800,  180.6500,  490.0200,  297.4800],\n",
      "        [ 785.8500,  179.6700, 1028.8199,  340.7500],\n",
      "        [ 711.9800,  179.6500,  848.8200,  277.6200],\n",
      "        [ 445.9100,  131.6900,  539.7700,  228.3600],\n",
      "        [ 660.8200,  178.7200,  713.0900,  222.0300],\n",
      "        [ 620.9500,  171.5900,  649.3600,  200.4600],\n",
      "        [ 547.6600,  172.9300,  591.2600,  194.0200],\n",
      "        [ 603.9200,  176.2500,  622.7500,  191.5800],\n",
      "        [1035.6000,  236.4800, 1240.0000,  373.0000]]),\n",
      "  'labels': tensor([0, 0, 0, 2, 0, 1, 8, 8, 8])},\n",
      " {'boxes': tensor([[ 638.1900,  176.1000,  666.1500,  199.2200],\n",
      "        [ 689.1000,  183.0300,  775.3000,  244.7700],\n",
      "        [ 852.7100,  187.0600, 1241.0000,  374.0000],\n",
      "        [ 705.4900,  175.2700,  743.1100,  201.0800],\n",
      "        [ 759.3400,  176.7500,  831.4700,  216.3600],\n",
      "        [ 944.4400,    0.0000, 1241.0000,  334.1400],\n",
      "        [ 550.1900,  165.6500,  559.6100,  177.1500],\n",
      "        [ 614.7700,  168.7700,  628.3500,  182.3500]]),\n",
      "  'labels': tensor([0, 0, 0, 0, 0, 2, 8, 8])},\n",
      " {'boxes': tensor([[716.0000, 143.8300, 898.5300, 263.8300],\n",
      "        [302.8400, 189.5900, 439.1100, 282.7600],\n",
      "        [424.4500, 184.9700, 489.7900, 231.1500],\n",
      "        [455.0600, 173.0900, 507.9600, 217.7400],\n",
      "        [580.6700, 171.0700, 607.9800, 195.9800],\n",
      "        [525.7300, 151.4200, 559.6600, 191.1700],\n",
      "        [565.8400, 171.4800, 579.7200, 193.7700]]),\n",
      "  'labels': tensor([0, 0, 0, 0, 0, 8, 8])},\n",
      " {'boxes': tensor([[ 828.7800,  178.3500, 1208.2600,  374.0000],\n",
      "        [ 444.5000,  161.4700,  548.4700,  258.6500],\n",
      "        [ 833.7900,  182.3500,  920.1000,  353.9000],\n",
      "        [   0.0000,  209.1500,  372.3700,  374.0000],\n",
      "        [ 714.9400,  183.7000,  803.0600,  240.7800],\n",
      "        [ 757.4800,  181.7600,  896.5300,  273.6000],\n",
      "        [ 558.2300,  173.8900,  590.9400,  204.8000],\n",
      "        [ 494.1800,  178.2700,  563.2300,  233.4700],\n",
      "        [ 707.3900,  179.3500,  768.0900,  226.2500],\n",
      "        [ 691.0300,  178.2600,  738.9900,  214.0800],\n",
      "        [ 679.5300,  176.8300,  720.4300,  208.0600],\n",
      "        [ 594.9500,  168.8900,  680.6300,  198.2900]]),\n",
      "  'labels': tensor([0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 8])})\n"
     ]
    }
   ],
   "source": [
    "import pprint as pp\n",
    "\n",
    "image, target = dataset[0]\n",
    "print(image)\n",
    "print(type(target))\n",
    "pp.pprint(target)\n",
    "\n",
    "\n",
    "print(\"data loader part\")\n",
    "for images, targets in data_loader:\n",
    "    print(len(images))\n",
    "    print(images[0].shape)\n",
    "    print(type(targets))\n",
    "    pp.pprint(targets)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train on gpu if available\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "\n",
    "# Define the list of classes\n",
    "class_list = ['Car', 'Van', 'Truck', 'Pedestrian', 'Person_sitting', 'Cyclist', 'Tram', 'Misc', 'DontCare']\n",
    "\n",
    "num_classes = len(class_list) # one class (class 0) is dedicated to the \"background\"\n",
    "\n",
    "# get the model using our helper function\n",
    "model = get_object_detection_model(num_classes)\n",
    "\n",
    "# move model to the right device\n",
    "model.to(device)\n",
    "\n",
    "# construct an optimizer\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "# and a learning rate scheduler which decreases the learning rate by\n",
    "# 10x every 3 epochs\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "  optimizer,\n",
    "  step_size=3,\n",
    "  gamma=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 374/374 [17:55<00:00,  2.88s/it]\n"
     ]
    }
   ],
   "source": [
    "# Function to evaluate the model\n",
    "def evaluate_model(model, data_loader, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    eval_results = []\n",
    "    with torch.no_grad():\n",
    "        for images, targets in tqdm(data_loader):\n",
    "            images = list(image.to(device) for image in images)\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "            outputs = model(images)\n",
    "            eval_results.append((outputs, targets))\n",
    "    return eval_results\n",
    "\n",
    "# Load the baseline model (pre-trained, unmodified)\n",
    "baseline_model = get_object_detection_model(num_classes)\n",
    "baseline_model.to(device)\n",
    "\n",
    "# Evaluate the baseline model\n",
    "baseline_eval_results = evaluate_model(baseline_model, data_loader_test, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # training for 5 epochs\n",
    "# num_epochs = 5\n",
    "\n",
    "# model_save_path = './models/faster_rcnn_kitti.pth'\n",
    "\n",
    "# # Training loop\n",
    "# num_epochs = 5\n",
    "# for epoch in range(num_epochs):\n",
    "#     train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=10)\n",
    "#     lr_scheduler.step()\n",
    "\n",
    "# # Save the model's state dictionary\n",
    "# torch.save(model.state_dict(), model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msazzadi14\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/sazzad14/Documents/Stanford/CS-231N/portalcut/detection/wandb/run-20240527_234344-z8n8or9t</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sazzadi14/fasterrcnn_resnet50_fpn_kitti/runs/z8n8or9t' target=\"_blank\">wandering-breeze-1</a></strong> to <a href='https://wandb.ai/sazzadi14/fasterrcnn_resnet50_fpn_kitti' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sazzadi14/fasterrcnn_resnet50_fpn_kitti' target=\"_blank\">https://wandb.ai/sazzadi14/fasterrcnn_resnet50_fpn_kitti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sazzadi14/fasterrcnn_resnet50_fpn_kitti/runs/z8n8or9t' target=\"_blank\">https://wandb.ai/sazzadi14/fasterrcnn_resnet50_fpn_kitti/runs/z8n8or9t</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "# Login to WandB (only needed if you haven't configured automatic login)\n",
    "wandb.login()\n",
    "\n",
    "num_epochs = 5\n",
    "\n",
    "# Initialize a new WandB run\n",
    "wandb.init(project=\"portalcut\",\n",
    "            entity='231n-augmentation', \n",
    "            notes=\"2024-05-28-kitti-test1-fasterrcnn_resnet50_fpn\",\n",
    "            \n",
    "            config={\n",
    "                \"learning_rate\": 0.005,\n",
    "                \"epochs\": num_epochs,\n",
    "                \"batch_size\": 4,\n",
    "                \"optimizer\": \"SGD\",\n",
    "                \"momentum\": 0.9,\n",
    "                \"weight_decay\": 0.0005,\n",
    "                \"lr_scheduler\": \"StepLR\",\n",
    "                \"step_size\": 3,\n",
    "                \"gamma\": 0.1\n",
    "            })\n",
    "config = wandb.config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0]  [   0/1497]  eta: 3:39:52  lr: 0.000000  loss: 0.8641 (0.8641)  loss_classifier: 0.4238 (0.4238)  loss_box_reg: 0.2727 (0.2727)  loss_objectness: 0.1330 (0.1330)  loss_rpn_box_reg: 0.0345 (0.0345)  time: 8.8123  data: 0.0892\n",
      "Epoch: [0]  [  10/1497]  eta: 3:27:59  lr: 0.000002  loss: 0.8237 (0.8513)  loss_classifier: 0.4143 (0.4299)  loss_box_reg: 0.2335 (0.2567)  loss_objectness: 0.0526 (0.0823)  loss_rpn_box_reg: 0.0758 (0.0824)  time: 8.3922  data: 0.0825\n",
      "Epoch: [0]  [  20/1497]  eta: 3:23:06  lr: 0.000003  loss: 0.8209 (0.8944)  loss_classifier: 0.3918 (0.4202)  loss_box_reg: 0.2260 (0.2471)  loss_objectness: 0.0597 (0.1279)  loss_rpn_box_reg: 0.0758 (0.0992)  time: 8.2225  data: 0.0815\n",
      "Epoch: [0]  [  30/1497]  eta: 3:18:37  lr: 0.000004  loss: 0.7025 (0.8502)  loss_classifier: 0.3786 (0.4088)  loss_box_reg: 0.2131 (0.2412)  loss_objectness: 0.0680 (0.1121)  loss_rpn_box_reg: 0.0603 (0.0881)  time: 7.9764  data: 0.0839\n",
      "Epoch: [0]  [  40/1497]  eta: 3:14:41  lr: 0.000005  loss: 0.7378 (0.8532)  loss_classifier: 0.3786 (0.4124)  loss_box_reg: 0.2131 (0.2463)  loss_objectness: 0.0722 (0.1111)  loss_rpn_box_reg: 0.0573 (0.0834)  time: 7.7726  data: 0.0839\n",
      "Epoch: [0]  [  50/1497]  eta: 3:13:24  lr: 0.000007  loss: 0.7771 (0.8127)  loss_classifier: 0.3775 (0.3988)  loss_box_reg: 0.2280 (0.2357)  loss_objectness: 0.0556 (0.1008)  loss_rpn_box_reg: 0.0476 (0.0773)  time: 7.8589  data: 0.0803\n",
      "Epoch: [0]  [  60/1497]  eta: 3:13:18  lr: 0.000008  loss: 0.7855 (0.8247)  loss_classifier: 0.4048 (0.4062)  loss_box_reg: 0.2662 (0.2455)  loss_objectness: 0.0535 (0.0984)  loss_rpn_box_reg: 0.0434 (0.0746)  time: 8.1823  data: 0.0829\n",
      "Epoch: [0]  [  70/1497]  eta: 3:09:43  lr: 0.000009  loss: 0.8325 (0.8176)  loss_classifier: 0.3928 (0.3980)  loss_box_reg: 0.2682 (0.2398)  loss_objectness: 0.0633 (0.1039)  loss_rpn_box_reg: 0.0495 (0.0759)  time: 7.8689  data: 0.0835\n",
      "Epoch: [0]  [  80/1497]  eta: 3:06:19  lr: 0.000011  loss: 0.7148 (0.8173)  loss_classifier: 0.3440 (0.3959)  loss_box_reg: 0.2032 (0.2393)  loss_objectness: 0.0923 (0.1071)  loss_rpn_box_reg: 0.0611 (0.0749)  time: 7.3351  data: 0.0808\n",
      "Epoch: [0]  [  90/1497]  eta: 3:03:04  lr: 0.000012  loss: 0.6887 (0.8114)  loss_classifier: 0.3571 (0.3931)  loss_box_reg: 0.2032 (0.2375)  loss_objectness: 0.0737 (0.1058)  loss_rpn_box_reg: 0.0611 (0.0750)  time: 7.2017  data: 0.0778\n",
      "Epoch: [0]  [ 100/1497]  eta: 3:01:32  lr: 0.000013  loss: 0.6727 (0.7986)  loss_classifier: 0.3401 (0.3856)  loss_box_reg: 0.1852 (0.2317)  loss_objectness: 0.0689 (0.1068)  loss_rpn_box_reg: 0.0545 (0.0745)  time: 7.4213  data: 0.0762\n",
      "Epoch: [0]  [ 110/1497]  eta: 2:59:36  lr: 0.000015  loss: 0.6727 (0.7901)  loss_classifier: 0.3392 (0.3812)  loss_box_reg: 0.1950 (0.2300)  loss_objectness: 0.0693 (0.1056)  loss_rpn_box_reg: 0.0495 (0.0733)  time: 7.5991  data: 0.0792\n",
      "Epoch: [0]  [ 120/1497]  eta: 2:57:36  lr: 0.000016  loss: 0.6982 (0.7890)  loss_classifier: 0.3580 (0.3798)  loss_box_reg: 0.2460 (0.2314)  loss_objectness: 0.0685 (0.1036)  loss_rpn_box_reg: 0.0534 (0.0742)  time: 7.4462  data: 0.0789\n",
      "Epoch: [0]  [ 130/1497]  eta: 2:55:33  lr: 0.000017  loss: 0.8094 (0.7880)  loss_classifier: 0.3750 (0.3785)  loss_box_reg: 0.2674 (0.2327)  loss_objectness: 0.0819 (0.1041)  loss_rpn_box_reg: 0.0534 (0.0727)  time: 7.3497  data: 0.0796\n",
      "Epoch: [0]  [ 140/1497]  eta: 2:53:59  lr: 0.000018  loss: 0.8094 (0.7914)  loss_classifier: 0.3482 (0.3761)  loss_box_reg: 0.2427 (0.2325)  loss_objectness: 0.0923 (0.1076)  loss_rpn_box_reg: 0.0428 (0.0752)  time: 7.4143  data: 0.0784\n",
      "Epoch: [0]  [ 150/1497]  eta: 2:52:29  lr: 0.000020  loss: 0.7801 (0.7916)  loss_classifier: 0.3357 (0.3764)  loss_box_reg: 0.2365 (0.2352)  loss_objectness: 0.0711 (0.1055)  loss_rpn_box_reg: 0.0659 (0.0745)  time: 7.5394  data: 0.0799\n",
      "Epoch: [0]  [ 160/1497]  eta: 2:50:26  lr: 0.000021  loss: 0.7026 (0.7873)  loss_classifier: 0.3281 (0.3736)  loss_box_reg: 0.2133 (0.2350)  loss_objectness: 0.0711 (0.1054)  loss_rpn_box_reg: 0.0519 (0.0733)  time: 7.3354  data: 0.0870\n",
      "Epoch: [0]  [ 170/1497]  eta: 2:48:37  lr: 0.000022  loss: 0.6073 (0.7753)  loss_classifier: 0.2822 (0.3687)  loss_box_reg: 0.1769 (0.2320)  loss_objectness: 0.0648 (0.1031)  loss_rpn_box_reg: 0.0304 (0.0715)  time: 7.1801  data: 0.0877\n",
      "Epoch: [0]  [ 180/1497]  eta: 2:46:57  lr: 0.000024  loss: 0.6401 (0.7727)  loss_classifier: 0.3163 (0.3678)  loss_box_reg: 0.2084 (0.2330)  loss_objectness: 0.0605 (0.1008)  loss_rpn_box_reg: 0.0424 (0.0710)  time: 7.2698  data: 0.0889\n",
      "Epoch: [0]  [ 190/1497]  eta: 2:45:46  lr: 0.000025  loss: 0.6467 (0.7787)  loss_classifier: 0.3292 (0.3668)  loss_box_reg: 0.2084 (0.2335)  loss_objectness: 0.0617 (0.1060)  loss_rpn_box_reg: 0.0619 (0.0724)  time: 7.4863  data: 0.0928\n",
      "Epoch: [0]  [ 200/1497]  eta: 2:44:32  lr: 0.000026  loss: 0.7412 (0.7841)  loss_classifier: 0.3049 (0.3654)  loss_box_reg: 0.2066 (0.2336)  loss_objectness: 0.0576 (0.1101)  loss_rpn_box_reg: 0.0807 (0.0750)  time: 7.6557  data: 0.0877\n",
      "Epoch: [0]  [ 210/1497]  eta: 2:43:26  lr: 0.000028  loss: 0.7727 (0.7856)  loss_classifier: 0.3487 (0.3653)  loss_box_reg: 0.2456 (0.2356)  loss_objectness: 0.0719 (0.1096)  loss_rpn_box_reg: 0.0797 (0.0752)  time: 7.7104  data: 0.0785\n",
      "Epoch: [0]  [ 220/1497]  eta: 2:42:19  lr: 0.000029  loss: 0.7747 (0.7893)  loss_classifier: 0.3551 (0.3656)  loss_box_reg: 0.2700 (0.2374)  loss_objectness: 0.0747 (0.1110)  loss_rpn_box_reg: 0.0611 (0.0754)  time: 7.7848  data: 0.0801\n",
      "Epoch: [0]  [ 230/1497]  eta: 2:40:56  lr: 0.000030  loss: 0.6435 (0.7780)  loss_classifier: 0.2589 (0.3603)  loss_box_reg: 0.1647 (0.2340)  loss_objectness: 0.0663 (0.1087)  loss_rpn_box_reg: 0.0475 (0.0750)  time: 7.6442  data: 0.0834\n",
      "Epoch: [0]  [ 240/1497]  eta: 2:39:35  lr: 0.000031  loss: 0.5158 (0.7718)  loss_classifier: 0.2445 (0.3578)  loss_box_reg: 0.1607 (0.2333)  loss_objectness: 0.0553 (0.1069)  loss_rpn_box_reg: 0.0410 (0.0738)  time: 7.5172  data: 0.0810\n",
      "Epoch: [0]  [ 250/1497]  eta: 2:38:08  lr: 0.000033  loss: 0.6521 (0.7741)  loss_classifier: 0.3179 (0.3591)  loss_box_reg: 0.2154 (0.2360)  loss_objectness: 0.0665 (0.1058)  loss_rpn_box_reg: 0.0520 (0.0732)  time: 7.4641  data: 0.0797\n",
      "Epoch: [0]  [ 260/1497]  eta: 2:36:42  lr: 0.000034  loss: 0.7351 (0.7740)  loss_classifier: 0.3473 (0.3582)  loss_box_reg: 0.2413 (0.2364)  loss_objectness: 0.0739 (0.1064)  loss_rpn_box_reg: 0.0557 (0.0731)  time: 7.3938  data: 0.0816\n",
      "Epoch: [0]  [ 270/1497]  eta: 2:35:25  lr: 0.000035  loss: 0.6741 (0.7730)  loss_classifier: 0.2899 (0.3578)  loss_box_reg: 0.2180 (0.2376)  loss_objectness: 0.0569 (0.1049)  loss_rpn_box_reg: 0.0505 (0.0727)  time: 7.4835  data: 0.0799\n",
      "Epoch: [0]  [ 280/1497]  eta: 2:34:06  lr: 0.000037  loss: 0.5895 (0.7657)  loss_classifier: 0.2886 (0.3545)  loss_box_reg: 0.2180 (0.2358)  loss_objectness: 0.0561 (0.1031)  loss_rpn_box_reg: 0.0475 (0.0723)  time: 7.5526  data: 0.0825\n",
      "Epoch: [0]  [ 290/1497]  eta: 2:32:49  lr: 0.000038  loss: 0.6119 (0.7640)  loss_classifier: 0.2973 (0.3537)  loss_box_reg: 0.2068 (0.2363)  loss_objectness: 0.0601 (0.1019)  loss_rpn_box_reg: 0.0535 (0.0721)  time: 7.5577  data: 0.0837\n",
      "Epoch: [0]  [ 300/1497]  eta: 2:31:38  lr: 0.000039  loss: 0.7683 (0.7632)  loss_classifier: 0.3086 (0.3528)  loss_box_reg: 0.2354 (0.2366)  loss_objectness: 0.0534 (0.1011)  loss_rpn_box_reg: 0.0642 (0.0727)  time: 7.6469  data: 0.0811\n",
      "Epoch: [0]  [ 310/1497]  eta: 2:30:38  lr: 0.000040  loss: 0.6561 (0.7606)  loss_classifier: 0.3012 (0.3515)  loss_box_reg: 0.2354 (0.2368)  loss_objectness: 0.0512 (0.0999)  loss_rpn_box_reg: 0.0534 (0.0724)  time: 7.8721  data: 0.0823\n",
      "Epoch: [0]  [ 320/1497]  eta: 2:29:35  lr: 0.000042  loss: 0.6561 (0.7627)  loss_classifier: 0.3012 (0.3522)  loss_box_reg: 0.2489 (0.2388)  loss_objectness: 0.0561 (0.0998)  loss_rpn_box_reg: 0.0408 (0.0718)  time: 8.0041  data: 0.0797\n",
      "Epoch: [0]  [ 330/1497]  eta: 2:28:30  lr: 0.000043  loss: 0.6638 (0.7637)  loss_classifier: 0.3155 (0.3522)  loss_box_reg: 0.2473 (0.2397)  loss_objectness: 0.0596 (0.1002)  loss_rpn_box_reg: 0.0547 (0.0716)  time: 7.9600  data: 0.0813\n",
      "Epoch: [0]  [ 340/1497]  eta: 2:27:22  lr: 0.000044  loss: 0.6585 (0.7625)  loss_classifier: 0.2984 (0.3519)  loss_box_reg: 0.2217 (0.2404)  loss_objectness: 0.0541 (0.0990)  loss_rpn_box_reg: 0.0508 (0.0713)  time: 7.9071  data: 0.0823\n",
      "Epoch: [0]  [ 350/1497]  eta: 2:26:10  lr: 0.000046  loss: 0.6186 (0.7594)  loss_classifier: 0.2632 (0.3500)  loss_box_reg: 0.2107 (0.2396)  loss_objectness: 0.0550 (0.0986)  loss_rpn_box_reg: 0.0412 (0.0713)  time: 7.8297  data: 0.0799\n",
      "Epoch: [0]  [ 360/1497]  eta: 2:25:00  lr: 0.000047  loss: 0.6259 (0.7600)  loss_classifier: 0.3061 (0.3503)  loss_box_reg: 0.2506 (0.2409)  loss_objectness: 0.0542 (0.0973)  loss_rpn_box_reg: 0.0631 (0.0715)  time: 7.8183  data: 0.0780\n",
      "Epoch: [0]  [ 370/1497]  eta: 2:23:50  lr: 0.000048  loss: 0.7157 (0.7594)  loss_classifier: 0.3348 (0.3500)  loss_box_reg: 0.2695 (0.2417)  loss_objectness: 0.0465 (0.0966)  loss_rpn_box_reg: 0.0631 (0.0712)  time: 7.8594  data: 0.0787\n",
      "Epoch: [0]  [ 380/1497]  eta: 2:22:42  lr: 0.000050  loss: 0.7163 (0.7565)  loss_classifier: 0.2896 (0.3486)  loss_box_reg: 0.2533 (0.2415)  loss_objectness: 0.0465 (0.0954)  loss_rpn_box_reg: 0.0587 (0.0711)  time: 7.9157  data: 0.0800\n",
      "Epoch: [0]  [ 390/1497]  eta: 2:21:29  lr: 0.000051  loss: 0.5736 (0.7530)  loss_classifier: 0.2693 (0.3465)  loss_box_reg: 0.2135 (0.2405)  loss_objectness: 0.0432 (0.0947)  loss_rpn_box_reg: 0.0591 (0.0714)  time: 7.8769  data: 0.0796\n",
      "Epoch: [0]  [ 400/1497]  eta: 2:20:14  lr: 0.000052  loss: 0.5426 (0.7533)  loss_classifier: 0.2628 (0.3450)  loss_box_reg: 0.1958 (0.2400)  loss_objectness: 0.0499 (0.0964)  loss_rpn_box_reg: 0.0611 (0.0718)  time: 7.7534  data: 0.0793\n",
      "Epoch: [0]  [ 410/1497]  eta: 2:19:00  lr: 0.000053  loss: 0.6419 (0.7514)  loss_classifier: 0.2964 (0.3442)  loss_box_reg: 0.2343 (0.2403)  loss_objectness: 0.0501 (0.0955)  loss_rpn_box_reg: 0.0599 (0.0714)  time: 7.7398  data: 0.0784\n",
      "Epoch: [0]  [ 420/1497]  eta: 2:17:47  lr: 0.000055  loss: 0.6859 (0.7506)  loss_classifier: 0.3180 (0.3433)  loss_box_reg: 0.2563 (0.2405)  loss_objectness: 0.0501 (0.0954)  loss_rpn_box_reg: 0.0440 (0.0714)  time: 7.8026  data: 0.0868\n",
      "Epoch: [0]  [ 430/1497]  eta: 2:16:35  lr: 0.000056  loss: 0.7307 (0.7487)  loss_classifier: 0.2770 (0.3425)  loss_box_reg: 0.2036 (0.2407)  loss_objectness: 0.0493 (0.0945)  loss_rpn_box_reg: 0.0412 (0.0710)  time: 7.8469  data: 0.0922\n",
      "Epoch: [0]  [ 440/1497]  eta: 2:15:19  lr: 0.000057  loss: 0.5609 (0.7459)  loss_classifier: 0.2761 (0.3413)  loss_box_reg: 0.2255 (0.2406)  loss_objectness: 0.0418 (0.0937)  loss_rpn_box_reg: 0.0396 (0.0703)  time: 7.7932  data: 0.0864\n",
      "Epoch: [0]  [ 450/1497]  eta: 2:14:06  lr: 0.000059  loss: 0.5609 (0.7454)  loss_classifier: 0.2761 (0.3406)  loss_box_reg: 0.2396 (0.2409)  loss_objectness: 0.0584 (0.0933)  loss_rpn_box_reg: 0.0426 (0.0706)  time: 7.7870  data: 0.0829\n",
      "Epoch: [0]  [ 460/1497]  eta: 2:12:52  lr: 0.000060  loss: 0.7243 (0.7446)  loss_classifier: 0.3017 (0.3398)  loss_box_reg: 0.2702 (0.2412)  loss_objectness: 0.0766 (0.0933)  loss_rpn_box_reg: 0.0487 (0.0703)  time: 7.8271  data: 0.0878\n",
      "Epoch: [0]  [ 470/1497]  eta: 2:11:39  lr: 0.000061  loss: 0.7306 (0.7445)  loss_classifier: 0.2989 (0.3395)  loss_box_reg: 0.2459 (0.2419)  loss_objectness: 0.0593 (0.0927)  loss_rpn_box_reg: 0.0487 (0.0704)  time: 7.8340  data: 0.0851\n",
      "Epoch: [0]  [ 480/1497]  eta: 2:10:27  lr: 0.000063  loss: 0.7447 (0.7460)  loss_classifier: 0.3544 (0.3398)  loss_box_reg: 0.3015 (0.2434)  loss_objectness: 0.0405 (0.0920)  loss_rpn_box_reg: 0.0710 (0.0708)  time: 7.8821  data: 0.0772\n",
      "Epoch: [0]  [ 490/1497]  eta: 2:09:09  lr: 0.000064  loss: 0.7059 (0.7453)  loss_classifier: 0.2967 (0.3389)  loss_box_reg: 0.2446 (0.2434)  loss_objectness: 0.0526 (0.0924)  loss_rpn_box_reg: 0.0441 (0.0707)  time: 7.7890  data: 0.0793\n",
      "Epoch: [0]  [ 500/1497]  eta: 2:07:51  lr: 0.000065  loss: 0.6043 (0.7429)  loss_classifier: 0.2619 (0.3376)  loss_box_reg: 0.2197 (0.2432)  loss_objectness: 0.0529 (0.0916)  loss_rpn_box_reg: 0.0417 (0.0705)  time: 7.6439  data: 0.0832\n",
      "Epoch: [0]  [ 510/1497]  eta: 2:06:36  lr: 0.000066  loss: 0.5967 (0.7401)  loss_classifier: 0.2573 (0.3363)  loss_box_reg: 0.2223 (0.2428)  loss_objectness: 0.0485 (0.0909)  loss_rpn_box_reg: 0.0301 (0.0702)  time: 7.7188  data: 0.0850\n",
      "Epoch: [0]  [ 520/1497]  eta: 2:05:21  lr: 0.000068  loss: 0.6268 (0.7397)  loss_classifier: 0.2836 (0.3358)  loss_box_reg: 0.2322 (0.2433)  loss_objectness: 0.0459 (0.0907)  loss_rpn_box_reg: 0.0358 (0.0699)  time: 7.8126  data: 0.0832\n",
      "Epoch: [0]  [ 530/1497]  eta: 2:04:07  lr: 0.000069  loss: 0.6690 (0.7384)  loss_classifier: 0.2782 (0.3350)  loss_box_reg: 0.2434 (0.2433)  loss_objectness: 0.0426 (0.0902)  loss_rpn_box_reg: 0.0439 (0.0699)  time: 7.8296  data: 0.0844\n",
      "Epoch: [0]  [ 540/1497]  eta: 2:02:52  lr: 0.000070  loss: 0.5595 (0.7352)  loss_classifier: 0.2463 (0.3335)  loss_box_reg: 0.1758 (0.2427)  loss_objectness: 0.0397 (0.0896)  loss_rpn_box_reg: 0.0381 (0.0694)  time: 7.8336  data: 0.0851\n",
      "Epoch: [0]  [ 550/1497]  eta: 2:01:39  lr: 0.000072  loss: 0.5442 (0.7346)  loss_classifier: 0.2666 (0.3331)  loss_box_reg: 0.2268 (0.2433)  loss_objectness: 0.0485 (0.0890)  loss_rpn_box_reg: 0.0319 (0.0692)  time: 7.8775  data: 0.0801\n",
      "Epoch: [0]  [ 560/1497]  eta: 2:00:27  lr: 0.000073  loss: 0.6208 (0.7335)  loss_classifier: 0.2723 (0.3324)  loss_box_reg: 0.2268 (0.2438)  loss_objectness: 0.0485 (0.0885)  loss_rpn_box_reg: 0.0319 (0.0689)  time: 7.9730  data: 0.0817\n",
      "Epoch: [0]  [ 570/1497]  eta: 1:59:15  lr: 0.000074  loss: 0.6096 (0.7301)  loss_classifier: 0.2552 (0.3306)  loss_box_reg: 0.2171 (0.2429)  loss_objectness: 0.0574 (0.0880)  loss_rpn_box_reg: 0.0366 (0.0687)  time: 8.0171  data: 0.0923\n",
      "Epoch: [0]  [ 580/1497]  eta: 1:58:02  lr: 0.000076  loss: 0.5659 (0.7286)  loss_classifier: 0.2459 (0.3299)  loss_box_reg: 0.2120 (0.2432)  loss_objectness: 0.0422 (0.0872)  loss_rpn_box_reg: 0.0419 (0.0683)  time: 8.0082  data: 0.0913\n",
      "Epoch: [0]  [ 590/1497]  eta: 1:56:50  lr: 0.000077  loss: 0.5184 (0.7256)  loss_classifier: 0.2374 (0.3284)  loss_box_reg: 0.2059 (0.2427)  loss_objectness: 0.0357 (0.0866)  loss_rpn_box_reg: 0.0401 (0.0679)  time: 8.0302  data: 0.0898\n",
      "Epoch: [0]  [ 600/1497]  eta: 1:55:35  lr: 0.000078  loss: 0.5252 (0.7239)  loss_classifier: 0.2362 (0.3274)  loss_box_reg: 0.2078 (0.2426)  loss_objectness: 0.0361 (0.0859)  loss_rpn_box_reg: 0.0435 (0.0679)  time: 7.9632  data: 0.0895\n",
      "Epoch: [0]  [ 610/1497]  eta: 1:54:24  lr: 0.000079  loss: 0.6156 (0.7222)  loss_classifier: 0.2362 (0.3261)  loss_box_reg: 0.2187 (0.2421)  loss_objectness: 0.0400 (0.0857)  loss_rpn_box_reg: 0.0627 (0.0684)  time: 8.0297  data: 0.0815\n",
      "Epoch: [0]  [ 620/1497]  eta: 1:53:10  lr: 0.000081  loss: 0.6374 (0.7217)  loss_classifier: 0.2672 (0.3258)  loss_box_reg: 0.2435 (0.2428)  loss_objectness: 0.0436 (0.0851)  loss_rpn_box_reg: 0.0552 (0.0681)  time: 8.0747  data: 0.0827\n",
      "Epoch: [0]  [ 630/1497]  eta: 1:51:53  lr: 0.000082  loss: 0.5301 (0.7176)  loss_classifier: 0.2579 (0.3239)  loss_box_reg: 0.2142 (0.2417)  loss_objectness: 0.0356 (0.0844)  loss_rpn_box_reg: 0.0371 (0.0677)  time: 7.8697  data: 0.0862\n",
      "Epoch: [0]  [ 640/1497]  eta: 1:50:41  lr: 0.000083  loss: 0.5318 (0.7171)  loss_classifier: 0.2629 (0.3234)  loss_box_reg: 0.2190 (0.2420)  loss_objectness: 0.0401 (0.0839)  loss_rpn_box_reg: 0.0492 (0.0677)  time: 7.9718  data: 0.0837\n",
      "Epoch: [0]  [ 650/1497]  eta: 1:49:24  lr: 0.000085  loss: 0.6312 (0.7151)  loss_classifier: 0.2916 (0.3224)  loss_box_reg: 0.2573 (0.2418)  loss_objectness: 0.0469 (0.0833)  loss_rpn_box_reg: 0.0430 (0.0676)  time: 7.9613  data: 0.0837\n",
      "Epoch: [0]  [ 660/1497]  eta: 1:48:09  lr: 0.000086  loss: 0.5257 (0.7127)  loss_classifier: 0.2268 (0.3212)  loss_box_reg: 0.2169 (0.2416)  loss_objectness: 0.0429 (0.0826)  loss_rpn_box_reg: 0.0431 (0.0673)  time: 7.8764  data: 0.0891\n",
      "Epoch: [0]  [ 670/1497]  eta: 1:46:54  lr: 0.000087  loss: 0.5660 (0.7150)  loss_classifier: 0.2455 (0.3207)  loss_box_reg: 0.2169 (0.2419)  loss_objectness: 0.0335 (0.0844)  loss_rpn_box_reg: 0.0451 (0.0680)  time: 7.9511  data: 0.0882\n",
      "Epoch: [0]  [ 680/1497]  eta: 1:45:38  lr: 0.000088  loss: 0.5021 (0.7132)  loss_classifier: 0.2455 (0.3193)  loss_box_reg: 0.1916 (0.2414)  loss_objectness: 0.0510 (0.0843)  loss_rpn_box_reg: 0.0588 (0.0682)  time: 7.9164  data: 0.0864\n",
      "Epoch: [0]  [ 690/1497]  eta: 1:44:20  lr: 0.000090  loss: 0.4919 (0.7126)  loss_classifier: 0.2105 (0.3190)  loss_box_reg: 0.1890 (0.2418)  loss_objectness: 0.0510 (0.0839)  loss_rpn_box_reg: 0.0508 (0.0679)  time: 7.8251  data: 0.0863\n",
      "Epoch: [0]  [ 700/1497]  eta: 1:43:04  lr: 0.000091  loss: 0.4919 (0.7116)  loss_classifier: 0.2263 (0.3184)  loss_box_reg: 0.1890 (0.2420)  loss_objectness: 0.0466 (0.0834)  loss_rpn_box_reg: 0.0447 (0.0677)  time: 7.8230  data: 0.0833\n",
      "Epoch: [0]  [ 710/1497]  eta: 1:41:48  lr: 0.000092  loss: 0.6147 (0.7108)  loss_classifier: 0.2711 (0.3178)  loss_box_reg: 0.2347 (0.2422)  loss_objectness: 0.0496 (0.0832)  loss_rpn_box_reg: 0.0584 (0.0677)  time: 7.8914  data: 0.0810\n",
      "Epoch: [0]  [ 720/1497]  eta: 1:40:30  lr: 0.000094  loss: 0.6093 (0.7087)  loss_classifier: 0.2507 (0.3166)  loss_box_reg: 0.2335 (0.2417)  loss_objectness: 0.0350 (0.0827)  loss_rpn_box_reg: 0.0584 (0.0677)  time: 7.8125  data: 0.0804\n",
      "Epoch: [0]  [ 730/1497]  eta: 1:39:13  lr: 0.000095  loss: 0.4605 (0.7055)  loss_classifier: 0.2059 (0.3149)  loss_box_reg: 0.1815 (0.2407)  loss_objectness: 0.0318 (0.0823)  loss_rpn_box_reg: 0.0504 (0.0676)  time: 7.7914  data: 0.0863\n",
      "Epoch: [0]  [ 740/1497]  eta: 1:37:55  lr: 0.000096  loss: 0.4934 (0.7051)  loss_classifier: 0.2247 (0.3144)  loss_box_reg: 0.2041 (0.2411)  loss_objectness: 0.0320 (0.0820)  loss_rpn_box_reg: 0.0536 (0.0676)  time: 7.7439  data: 0.0866\n",
      "Epoch: [0]  [ 750/1497]  eta: 1:36:36  lr: 0.000098  loss: 0.6009 (0.7039)  loss_classifier: 0.2680 (0.3138)  loss_box_reg: 0.2451 (0.2412)  loss_objectness: 0.0446 (0.0815)  loss_rpn_box_reg: 0.0459 (0.0674)  time: 7.6650  data: 0.0770\n",
      "Epoch: [0]  [ 760/1497]  eta: 1:35:17  lr: 0.000099  loss: 0.6282 (0.7053)  loss_classifier: 0.2800 (0.3140)  loss_box_reg: 0.2552 (0.2421)  loss_objectness: 0.0445 (0.0813)  loss_rpn_box_reg: 0.0556 (0.0679)  time: 7.6317  data: 0.0714\n",
      "Epoch: [0]  [ 770/1497]  eta: 1:33:58  lr: 0.000100  loss: 0.6112 (0.7047)  loss_classifier: 0.2774 (0.3132)  loss_box_reg: 0.2463 (0.2421)  loss_objectness: 0.0381 (0.0812)  loss_rpn_box_reg: 0.0719 (0.0682)  time: 7.5971  data: 0.0773\n",
      "Epoch: [0]  [ 780/1497]  eta: 1:32:41  lr: 0.000101  loss: 0.6422 (0.7048)  loss_classifier: 0.2492 (0.3130)  loss_box_reg: 0.2470 (0.2428)  loss_objectness: 0.0396 (0.0808)  loss_rpn_box_reg: 0.0580 (0.0682)  time: 7.7210  data: 0.0812\n",
      "Epoch: [0]  [ 790/1497]  eta: 1:31:22  lr: 0.000103  loss: 0.6422 (0.7037)  loss_classifier: 0.2553 (0.3123)  loss_box_reg: 0.2540 (0.2429)  loss_objectness: 0.0507 (0.0807)  loss_rpn_box_reg: 0.0355 (0.0677)  time: 7.7249  data: 0.0771\n",
      "Epoch: [0]  [ 800/1497]  eta: 1:30:05  lr: 0.000104  loss: 0.6334 (0.7034)  loss_classifier: 0.2730 (0.3119)  loss_box_reg: 0.2703 (0.2434)  loss_objectness: 0.0443 (0.0805)  loss_rpn_box_reg: 0.0350 (0.0676)  time: 7.6980  data: 0.0791\n",
      "Epoch: [0]  [ 810/1497]  eta: 1:28:49  lr: 0.000105  loss: 0.6334 (0.7023)  loss_classifier: 0.2722 (0.3112)  loss_box_reg: 0.2382 (0.2434)  loss_objectness: 0.0417 (0.0802)  loss_rpn_box_reg: 0.0462 (0.0674)  time: 7.8366  data: 0.0809\n",
      "Epoch: [0]  [ 820/1497]  eta: 1:27:31  lr: 0.000107  loss: 0.5358 (0.7016)  loss_classifier: 0.2375 (0.3108)  loss_box_reg: 0.2078 (0.2438)  loss_objectness: 0.0417 (0.0798)  loss_rpn_box_reg: 0.0408 (0.0672)  time: 7.8031  data: 0.0760\n",
      "Epoch: [0]  [ 830/1497]  eta: 1:26:13  lr: 0.000108  loss: 0.5358 (0.7000)  loss_classifier: 0.2375 (0.3099)  loss_box_reg: 0.2322 (0.2437)  loss_objectness: 0.0399 (0.0794)  loss_rpn_box_reg: 0.0372 (0.0669)  time: 7.7565  data: 0.0776\n",
      "Epoch: [0]  [ 840/1497]  eta: 1:24:57  lr: 0.000109  loss: 0.5772 (0.6981)  loss_classifier: 0.2396 (0.3090)  loss_box_reg: 0.2285 (0.2433)  loss_objectness: 0.0399 (0.0792)  loss_rpn_box_reg: 0.0274 (0.0666)  time: 7.8599  data: 0.0844\n",
      "Epoch: [0]  [ 850/1497]  eta: 1:23:41  lr: 0.000111  loss: 0.6222 (0.6988)  loss_classifier: 0.2653 (0.3086)  loss_box_reg: 0.2340 (0.2436)  loss_objectness: 0.0416 (0.0797)  loss_rpn_box_reg: 0.0392 (0.0669)  time: 7.9241  data: 0.0811\n",
      "Epoch: [0]  [ 860/1497]  eta: 1:22:24  lr: 0.000112  loss: 0.6222 (0.6979)  loss_classifier: 0.2616 (0.3079)  loss_box_reg: 0.2373 (0.2437)  loss_objectness: 0.0397 (0.0794)  loss_rpn_box_reg: 0.0627 (0.0668)  time: 7.9135  data: 0.0827\n",
      "Epoch: [0]  [ 870/1497]  eta: 1:21:07  lr: 0.000113  loss: 0.6446 (0.7012)  loss_classifier: 0.2585 (0.3075)  loss_box_reg: 0.2516 (0.2438)  loss_objectness: 0.0432 (0.0815)  loss_rpn_box_reg: 0.0712 (0.0684)  time: 7.8806  data: 0.0858\n",
      "Epoch: [0]  [ 880/1497]  eta: 1:19:51  lr: 0.000114  loss: 0.5643 (0.7000)  loss_classifier: 0.2363 (0.3068)  loss_box_reg: 0.2460 (0.2438)  loss_objectness: 0.0462 (0.0812)  loss_rpn_box_reg: 0.0523 (0.0682)  time: 7.8829  data: 0.0827\n",
      "Epoch: [0]  [ 890/1497]  eta: 1:18:33  lr: 0.000116  loss: 0.5245 (0.6992)  loss_classifier: 0.2233 (0.3060)  loss_box_reg: 0.2366 (0.2436)  loss_objectness: 0.0427 (0.0810)  loss_rpn_box_reg: 0.0404 (0.0685)  time: 7.8546  data: 0.0850\n",
      "Epoch: [0]  [ 900/1497]  eta: 1:17:16  lr: 0.000117  loss: 0.5666 (0.6985)  loss_classifier: 0.2427 (0.3055)  loss_box_reg: 0.2343 (0.2439)  loss_objectness: 0.0566 (0.0809)  loss_rpn_box_reg: 0.0438 (0.0683)  time: 7.8413  data: 0.0809\n",
      "Epoch: [0]  [ 910/1497]  eta: 1:16:00  lr: 0.000118  loss: 0.5666 (0.6971)  loss_classifier: 0.2427 (0.3047)  loss_box_reg: 0.2343 (0.2436)  loss_objectness: 0.0477 (0.0806)  loss_rpn_box_reg: 0.0454 (0.0681)  time: 7.8936  data: 0.0757\n",
      "Epoch: [0]  [ 920/1497]  eta: 1:14:42  lr: 0.000120  loss: 0.5602 (0.6957)  loss_classifier: 0.2196 (0.3039)  loss_box_reg: 0.2269 (0.2436)  loss_objectness: 0.0477 (0.0803)  loss_rpn_box_reg: 0.0479 (0.0679)  time: 7.8234  data: 0.0834\n",
      "Epoch: [0]  [ 930/1497]  eta: 1:13:25  lr: 0.000121  loss: 0.6154 (0.6953)  loss_classifier: 0.2496 (0.3034)  loss_box_reg: 0.2476 (0.2437)  loss_objectness: 0.0434 (0.0803)  loss_rpn_box_reg: 0.0479 (0.0680)  time: 7.8108  data: 0.0858\n",
      "Epoch: [0]  [ 940/1497]  eta: 1:12:08  lr: 0.000122  loss: 0.5811 (0.6938)  loss_classifier: 0.2441 (0.3025)  loss_box_reg: 0.2476 (0.2435)  loss_objectness: 0.0409 (0.0800)  loss_rpn_box_reg: 0.0454 (0.0678)  time: 7.9491  data: 0.0786\n",
      "Epoch: [0]  [ 950/1497]  eta: 1:10:51  lr: 0.000124  loss: 0.5834 (0.6963)  loss_classifier: 0.2497 (0.3020)  loss_box_reg: 0.2436 (0.2436)  loss_objectness: 0.0409 (0.0819)  loss_rpn_box_reg: 0.0722 (0.0689)  time: 7.9463  data: 0.0761\n",
      "Epoch: [0]  [ 960/1497]  eta: 1:09:34  lr: 0.000125  loss: 0.7105 (0.6958)  loss_classifier: 0.2776 (0.3016)  loss_box_reg: 0.2606 (0.2439)  loss_objectness: 0.0549 (0.0816)  loss_rpn_box_reg: 0.0583 (0.0686)  time: 7.8765  data: 0.0771\n",
      "Epoch: [0]  [ 970/1497]  eta: 1:08:17  lr: 0.000126  loss: 0.5852 (0.6951)  loss_classifier: 0.2294 (0.3011)  loss_box_reg: 0.2627 (0.2440)  loss_objectness: 0.0549 (0.0814)  loss_rpn_box_reg: 0.0414 (0.0686)  time: 7.8702  data: 0.0798\n",
      "Epoch: [0]  [ 980/1497]  eta: 1:07:00  lr: 0.000127  loss: 0.5112 (0.6940)  loss_classifier: 0.2057 (0.3002)  loss_box_reg: 0.2163 (0.2438)  loss_objectness: 0.0449 (0.0812)  loss_rpn_box_reg: 0.0755 (0.0688)  time: 7.8569  data: 0.0778\n",
      "Epoch: [0]  [ 990/1497]  eta: 1:05:43  lr: 0.000129  loss: 0.5549 (0.6929)  loss_classifier: 0.2226 (0.2995)  loss_box_reg: 0.2163 (0.2435)  loss_objectness: 0.0608 (0.0810)  loss_rpn_box_reg: 0.0598 (0.0688)  time: 7.8761  data: 0.0790\n",
      "Epoch: [0]  [1000/1497]  eta: 1:04:25  lr: 0.000130  loss: 0.5549 (0.6921)  loss_classifier: 0.2226 (0.2991)  loss_box_reg: 0.2001 (0.2437)  loss_objectness: 0.0568 (0.0806)  loss_rpn_box_reg: 0.0478 (0.0687)  time: 7.8226  data: 0.0860\n",
      "Epoch: [0]  [1010/1497]  eta: 1:03:07  lr: 0.000130  loss: 0.6840 (0.6929)  loss_classifier: 0.2449 (0.2988)  loss_box_reg: 0.2617 (0.2439)  loss_objectness: 0.0407 (0.0812)  loss_rpn_box_reg: 0.0401 (0.0690)  time: 7.7777  data: 0.0823\n",
      "Epoch: [0]  [1020/1497]  eta: 1:01:49  lr: 0.000130  loss: 0.6249 (0.6916)  loss_classifier: 0.2686 (0.2982)  loss_box_reg: 0.2664 (0.2439)  loss_objectness: 0.0319 (0.0808)  loss_rpn_box_reg: 0.0395 (0.0688)  time: 7.8143  data: 0.0771\n",
      "Epoch: [0]  [1030/1497]  eta: 1:00:31  lr: 0.000130  loss: 0.5373 (0.6901)  loss_classifier: 0.2187 (0.2974)  loss_box_reg: 0.2470 (0.2436)  loss_objectness: 0.0298 (0.0804)  loss_rpn_box_reg: 0.0365 (0.0687)  time: 7.7038  data: 0.0764\n",
      "Epoch: [0]  [1040/1497]  eta: 0:59:13  lr: 0.000130  loss: 0.5970 (0.6905)  loss_classifier: 0.2550 (0.2974)  loss_box_reg: 0.2739 (0.2443)  loss_objectness: 0.0372 (0.0801)  loss_rpn_box_reg: 0.0477 (0.0687)  time: 7.7121  data: 0.0767\n",
      "Epoch: [0]  [1050/1497]  eta: 0:57:56  lr: 0.000130  loss: 0.6010 (0.6888)  loss_classifier: 0.2438 (0.2965)  loss_box_reg: 0.2625 (0.2441)  loss_objectness: 0.0347 (0.0797)  loss_rpn_box_reg: 0.0477 (0.0685)  time: 7.8550  data: 0.0834\n",
      "Epoch: [0]  [1060/1497]  eta: 0:56:39  lr: 0.000130  loss: 0.4664 (0.6877)  loss_classifier: 0.1747 (0.2960)  loss_box_reg: 0.2166 (0.2440)  loss_objectness: 0.0347 (0.0793)  loss_rpn_box_reg: 0.0358 (0.0684)  time: 7.9075  data: 0.0857\n",
      "Epoch: [0]  [1070/1497]  eta: 0:55:22  lr: 0.000130  loss: 0.4903 (0.6861)  loss_classifier: 0.2248 (0.2951)  loss_box_reg: 0.2302 (0.2436)  loss_objectness: 0.0362 (0.0790)  loss_rpn_box_reg: 0.0479 (0.0683)  time: 7.9442  data: 0.0843\n",
      "Epoch: [0]  [1080/1497]  eta: 0:54:04  lr: 0.000130  loss: 0.4903 (0.6854)  loss_classifier: 0.1929 (0.2946)  loss_box_reg: 0.1957 (0.2436)  loss_objectness: 0.0386 (0.0789)  loss_rpn_box_reg: 0.0492 (0.0682)  time: 7.9128  data: 0.0834\n",
      "Epoch: [0]  [1090/1497]  eta: 0:52:46  lr: 0.000130  loss: 0.5323 (0.6861)  loss_classifier: 0.2087 (0.2941)  loss_box_reg: 0.2098 (0.2437)  loss_objectness: 0.0404 (0.0797)  loss_rpn_box_reg: 0.0394 (0.0686)  time: 7.7901  data: 0.0812\n",
      "Epoch: [0]  [1100/1497]  eta: 0:51:29  lr: 0.000130  loss: 0.5581 (0.6863)  loss_classifier: 0.2331 (0.2939)  loss_box_reg: 0.2533 (0.2442)  loss_objectness: 0.0404 (0.0795)  loss_rpn_box_reg: 0.0640 (0.0688)  time: 7.8227  data: 0.0850\n",
      "Epoch: [0]  [1110/1497]  eta: 0:50:11  lr: 0.000130  loss: 0.5568 (0.6855)  loss_classifier: 0.2331 (0.2934)  loss_box_reg: 0.2497 (0.2440)  loss_objectness: 0.0455 (0.0794)  loss_rpn_box_reg: 0.0735 (0.0688)  time: 7.8688  data: 0.0843\n",
      "Epoch: [0]  [1120/1497]  eta: 0:48:54  lr: 0.000130  loss: 0.5188 (0.6838)  loss_classifier: 0.2125 (0.2925)  loss_box_reg: 0.1930 (0.2436)  loss_objectness: 0.0318 (0.0789)  loss_rpn_box_reg: 0.0511 (0.0687)  time: 7.9258  data: 0.0825\n",
      "Epoch: [0]  [1130/1497]  eta: 0:47:36  lr: 0.000130  loss: 0.5446 (0.6834)  loss_classifier: 0.2139 (0.2921)  loss_box_reg: 0.2376 (0.2438)  loss_objectness: 0.0318 (0.0788)  loss_rpn_box_reg: 0.0511 (0.0688)  time: 7.9213  data: 0.0820\n",
      "Epoch: [0]  [1140/1497]  eta: 0:46:19  lr: 0.000130  loss: 0.5890 (0.6831)  loss_classifier: 0.2367 (0.2918)  loss_box_reg: 0.2549 (0.2441)  loss_objectness: 0.0452 (0.0784)  loss_rpn_box_reg: 0.0574 (0.0688)  time: 7.7938  data: 0.0820\n",
      "Epoch: [0]  [1150/1497]  eta: 0:45:01  lr: 0.000130  loss: 0.5658 (0.6818)  loss_classifier: 0.1990 (0.2910)  loss_box_reg: 0.2346 (0.2438)  loss_objectness: 0.0371 (0.0781)  loss_rpn_box_reg: 0.0428 (0.0689)  time: 7.8875  data: 0.0839\n",
      "Epoch: [0]  [1160/1497]  eta: 0:43:43  lr: 0.000130  loss: 0.4857 (0.6812)  loss_classifier: 0.1891 (0.2906)  loss_box_reg: 0.1978 (0.2440)  loss_objectness: 0.0371 (0.0778)  loss_rpn_box_reg: 0.0428 (0.0688)  time: 7.8687  data: 0.0854\n",
      "Epoch: [0]  [1170/1497]  eta: 0:42:26  lr: 0.000130  loss: 0.4857 (0.6796)  loss_classifier: 0.1923 (0.2898)  loss_box_reg: 0.1988 (0.2436)  loss_objectness: 0.0369 (0.0775)  loss_rpn_box_reg: 0.0460 (0.0687)  time: 7.7775  data: 0.0855\n",
      "Epoch: [0]  [1180/1497]  eta: 0:41:08  lr: 0.000130  loss: 0.4718 (0.6782)  loss_classifier: 0.1923 (0.2890)  loss_box_reg: 0.1856 (0.2434)  loss_objectness: 0.0367 (0.0773)  loss_rpn_box_reg: 0.0460 (0.0685)  time: 7.7956  data: 0.0821\n",
      "Epoch: [0]  [1190/1497]  eta: 0:39:50  lr: 0.000130  loss: 0.5170 (0.6778)  loss_classifier: 0.1929 (0.2887)  loss_box_reg: 0.2335 (0.2437)  loss_objectness: 0.0320 (0.0769)  loss_rpn_box_reg: 0.0463 (0.0685)  time: 7.7977  data: 0.0820\n",
      "Epoch: [0]  [1200/1497]  eta: 0:38:32  lr: 0.000130  loss: 0.4910 (0.6763)  loss_classifier: 0.1859 (0.2880)  loss_box_reg: 0.1759 (0.2434)  loss_objectness: 0.0347 (0.0766)  loss_rpn_box_reg: 0.0495 (0.0683)  time: 7.7906  data: 0.0827\n",
      "Epoch: [0]  [1210/1497]  eta: 0:37:14  lr: 0.000130  loss: 0.4778 (0.6756)  loss_classifier: 0.1822 (0.2875)  loss_box_reg: 0.1800 (0.2434)  loss_objectness: 0.0413 (0.0764)  loss_rpn_box_reg: 0.0478 (0.0682)  time: 7.7463  data: 0.0866\n",
      "Epoch: [0]  [1220/1497]  eta: 0:35:56  lr: 0.000130  loss: 0.4778 (0.6736)  loss_classifier: 0.2076 (0.2867)  loss_box_reg: 0.2091 (0.2430)  loss_objectness: 0.0376 (0.0760)  loss_rpn_box_reg: 0.0408 (0.0679)  time: 7.7741  data: 0.0885\n",
      "Epoch: [0]  [1230/1497]  eta: 0:34:39  lr: 0.000130  loss: 0.4902 (0.6735)  loss_classifier: 0.2001 (0.2860)  loss_box_reg: 0.2052 (0.2428)  loss_objectness: 0.0326 (0.0765)  loss_rpn_box_reg: 0.0371 (0.0681)  time: 7.8837  data: 0.0823\n",
      "Epoch: [0]  [1240/1497]  eta: 0:33:21  lr: 0.000130  loss: 0.4995 (0.6723)  loss_classifier: 0.2001 (0.2855)  loss_box_reg: 0.2052 (0.2426)  loss_objectness: 0.0357 (0.0761)  loss_rpn_box_reg: 0.0426 (0.0680)  time: 7.8166  data: 0.0808\n",
      "Epoch: [0]  [1250/1497]  eta: 0:32:03  lr: 0.000130  loss: 0.4889 (0.6722)  loss_classifier: 0.1905 (0.2851)  loss_box_reg: 0.2065 (0.2428)  loss_objectness: 0.0357 (0.0762)  loss_rpn_box_reg: 0.0519 (0.0681)  time: 7.7262  data: 0.0795\n",
      "Epoch: [0]  [1260/1497]  eta: 0:30:45  lr: 0.000130  loss: 0.4998 (0.6713)  loss_classifier: 0.2001 (0.2846)  loss_box_reg: 0.2065 (0.2427)  loss_objectness: 0.0462 (0.0759)  loss_rpn_box_reg: 0.0518 (0.0681)  time: 7.7054  data: 0.0757\n",
      "Epoch: [0]  [1270/1497]  eta: 0:29:26  lr: 0.000130  loss: 0.5997 (0.6711)  loss_classifier: 0.2281 (0.2844)  loss_box_reg: 0.2203 (0.2430)  loss_objectness: 0.0375 (0.0757)  loss_rpn_box_reg: 0.0412 (0.0680)  time: 7.5844  data: 0.0767\n",
      "Epoch: [0]  [1280/1497]  eta: 0:28:08  lr: 0.000130  loss: 0.6105 (0.6705)  loss_classifier: 0.2478 (0.2840)  loss_box_reg: 0.2623 (0.2430)  loss_objectness: 0.0343 (0.0755)  loss_rpn_box_reg: 0.0536 (0.0680)  time: 7.5872  data: 0.0766\n",
      "Epoch: [0]  [1290/1497]  eta: 0:26:50  lr: 0.000130  loss: 0.5020 (0.6689)  loss_classifier: 0.1974 (0.2832)  loss_box_reg: 0.2087 (0.2426)  loss_objectness: 0.0311 (0.0752)  loss_rpn_box_reg: 0.0458 (0.0679)  time: 7.7102  data: 0.0833\n",
      "Epoch: [0]  [1300/1497]  eta: 0:25:33  lr: 0.000130  loss: 0.4103 (0.6675)  loss_classifier: 0.1578 (0.2824)  loss_box_reg: 0.1543 (0.2421)  loss_objectness: 0.0375 (0.0751)  loss_rpn_box_reg: 0.0530 (0.0679)  time: 7.7839  data: 0.0855\n",
      "Epoch: [0]  [1310/1497]  eta: 0:24:15  lr: 0.000130  loss: 0.5230 (0.6673)  loss_classifier: 0.1803 (0.2821)  loss_box_reg: 0.1700 (0.2420)  loss_objectness: 0.0515 (0.0752)  loss_rpn_box_reg: 0.0589 (0.0680)  time: 7.7619  data: 0.0800\n",
      "Epoch: [0]  [1320/1497]  eta: 0:22:57  lr: 0.000130  loss: 0.6060 (0.6674)  loss_classifier: 0.2455 (0.2820)  loss_box_reg: 0.2296 (0.2424)  loss_objectness: 0.0545 (0.0749)  loss_rpn_box_reg: 0.0858 (0.0681)  time: 7.7470  data: 0.0812\n",
      "Epoch: [0]  [1330/1497]  eta: 0:21:39  lr: 0.000130  loss: 0.5866 (0.6662)  loss_classifier: 0.2224 (0.2814)  loss_box_reg: 0.2213 (0.2421)  loss_objectness: 0.0395 (0.0748)  loss_rpn_box_reg: 0.0528 (0.0680)  time: 7.8192  data: 0.0804\n",
      "Epoch: [0]  [1340/1497]  eta: 0:20:21  lr: 0.000130  loss: 0.5007 (0.6652)  loss_classifier: 0.1746 (0.2809)  loss_box_reg: 0.1971 (0.2421)  loss_objectness: 0.0386 (0.0744)  loss_rpn_box_reg: 0.0371 (0.0677)  time: 7.8549  data: 0.0777\n",
      "Epoch: [0]  [1350/1497]  eta: 0:19:04  lr: 0.000130  loss: 0.5007 (0.6642)  loss_classifier: 0.1994 (0.2804)  loss_box_reg: 0.2043 (0.2420)  loss_objectness: 0.0324 (0.0742)  loss_rpn_box_reg: 0.0321 (0.0676)  time: 7.8200  data: 0.0764\n",
      "Epoch: [0]  [1360/1497]  eta: 0:17:46  lr: 0.000130  loss: 0.5217 (0.6636)  loss_classifier: 0.2044 (0.2800)  loss_box_reg: 0.2069 (0.2419)  loss_objectness: 0.0404 (0.0741)  loss_rpn_box_reg: 0.0471 (0.0677)  time: 7.7668  data: 0.0794\n",
      "Epoch: [0]  [1370/1497]  eta: 0:16:28  lr: 0.000130  loss: 0.5394 (0.6625)  loss_classifier: 0.2117 (0.2794)  loss_box_reg: 0.2216 (0.2416)  loss_objectness: 0.0409 (0.0739)  loss_rpn_box_reg: 0.0507 (0.0676)  time: 7.6763  data: 0.0823\n",
      "Epoch: [0]  [1380/1497]  eta: 0:15:10  lr: 0.000130  loss: 0.5781 (0.6625)  loss_classifier: 0.2380 (0.2793)  loss_box_reg: 0.2633 (0.2419)  loss_objectness: 0.0363 (0.0737)  loss_rpn_box_reg: 0.0507 (0.0677)  time: 7.7344  data: 0.0813\n",
      "Epoch: [0]  [1390/1497]  eta: 0:13:52  lr: 0.000130  loss: 0.6008 (0.6622)  loss_classifier: 0.2380 (0.2790)  loss_box_reg: 0.2656 (0.2420)  loss_objectness: 0.0392 (0.0736)  loss_rpn_box_reg: 0.0417 (0.0675)  time: 7.8749  data: 0.0823\n",
      "Epoch: [0]  [1400/1497]  eta: 0:12:34  lr: 0.000130  loss: 0.5929 (0.6611)  loss_classifier: 0.2144 (0.2785)  loss_box_reg: 0.2358 (0.2418)  loss_objectness: 0.0423 (0.0734)  loss_rpn_box_reg: 0.0389 (0.0674)  time: 7.8476  data: 0.0810\n",
      "Epoch: [0]  [1410/1497]  eta: 0:11:17  lr: 0.000130  loss: 0.4371 (0.6595)  loss_classifier: 0.1781 (0.2778)  loss_box_reg: 0.1640 (0.2414)  loss_objectness: 0.0295 (0.0731)  loss_rpn_box_reg: 0.0343 (0.0672)  time: 7.7598  data: 0.0803\n",
      "Epoch: [0]  [1420/1497]  eta: 0:09:59  lr: 0.000130  loss: 0.5281 (0.6593)  loss_classifier: 0.1935 (0.2775)  loss_box_reg: 0.2066 (0.2416)  loss_objectness: 0.0313 (0.0729)  loss_rpn_box_reg: 0.0331 (0.0673)  time: 7.7501  data: 0.0825\n",
      "Epoch: [0]  [1430/1497]  eta: 0:08:41  lr: 0.000130  loss: 0.5681 (0.6582)  loss_classifier: 0.2231 (0.2770)  loss_box_reg: 0.2078 (0.2414)  loss_objectness: 0.0386 (0.0726)  loss_rpn_box_reg: 0.0438 (0.0673)  time: 7.6996  data: 0.0826\n",
      "Epoch: [0]  [1440/1497]  eta: 0:07:23  lr: 0.000130  loss: 0.4643 (0.6572)  loss_classifier: 0.1778 (0.2763)  loss_box_reg: 0.1765 (0.2411)  loss_objectness: 0.0296 (0.0725)  loss_rpn_box_reg: 0.0444 (0.0672)  time: 7.6184  data: 0.0824\n",
      "Epoch: [0]  [1450/1497]  eta: 0:06:05  lr: 0.000130  loss: 0.4974 (0.6566)  loss_classifier: 0.1852 (0.2759)  loss_box_reg: 0.1881 (0.2411)  loss_objectness: 0.0283 (0.0722)  loss_rpn_box_reg: 0.0572 (0.0674)  time: 7.5279  data: 0.0824\n",
      "Epoch: [0]  [1460/1497]  eta: 0:04:47  lr: 0.000130  loss: 0.4816 (0.6556)  loss_classifier: 0.1977 (0.2754)  loss_box_reg: 0.1920 (0.2410)  loss_objectness: 0.0299 (0.0720)  loss_rpn_box_reg: 0.0572 (0.0672)  time: 7.4201  data: 0.0802\n",
      "Epoch: [0]  [1470/1497]  eta: 0:03:29  lr: 0.000130  loss: 0.4396 (0.6551)  loss_classifier: 0.1748 (0.2751)  loss_box_reg: 0.1944 (0.2411)  loss_objectness: 0.0374 (0.0718)  loss_rpn_box_reg: 0.0428 (0.0671)  time: 7.3719  data: 0.0790\n",
      "Epoch: [0]  [1480/1497]  eta: 0:02:12  lr: 0.000130  loss: 0.5127 (0.6543)  loss_classifier: 0.2006 (0.2747)  loss_box_reg: 0.2216 (0.2410)  loss_objectness: 0.0412 (0.0716)  loss_rpn_box_reg: 0.0428 (0.0670)  time: 7.3957  data: 0.0772\n",
      "Epoch: [0]  [1490/1497]  eta: 0:00:54  lr: 0.000130  loss: 0.5657 (0.6537)  loss_classifier: 0.2004 (0.2742)  loss_box_reg: 0.2280 (0.2410)  loss_objectness: 0.0428 (0.0715)  loss_rpn_box_reg: 0.0443 (0.0670)  time: 7.4039  data: 0.0777\n",
      "Epoch: [0]  [1496/1497]  eta: 0:00:07  lr: 0.000130  loss: 0.5551 (0.6529)  loss_classifier: 0.1832 (0.2738)  loss_box_reg: 0.2093 (0.2408)  loss_objectness: 0.0396 (0.0714)  loss_rpn_box_reg: 0.0441 (0.0669)  time: 7.1789  data: 0.0790\n",
      "Epoch: [0] Total time: 3:13:41 (7.7631 s / it)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Path is not a file: ./models/fasterrcnn_resnet50_fpn_kitti.pth",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 71\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# Optional: log the model artifact at the end of each epoch\u001b[39;00m\n\u001b[1;32m     70\u001b[0m     model_artifact \u001b[38;5;241m=\u001b[39m wandb\u001b[38;5;241m.\u001b[39mArtifact(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfasterrcnn_resnet50_fpn_kitti\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m, description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining model state dict\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 71\u001b[0m     \u001b[43mmodel_artifact\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_save_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m     wandb\u001b[38;5;241m.\u001b[39mlog_artifact(model_artifact)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# Finish WandB run\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Stanford/CS-231N/portalcut/.venv/lib/python3.11/site-packages/wandb/sdk/artifacts/artifact.py:1185\u001b[0m, in \u001b[0;36mArtifact.add_file\u001b[0;34m(self, local_path, name, is_tmp, skip_cache, policy)\u001b[0m\n\u001b[1;32m   1183\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_can_add()\n\u001b[1;32m   1184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(local_path):\n\u001b[0;32m-> 1185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPath is not a file: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m local_path)\n\u001b[1;32m   1187\u001b[0m name \u001b[38;5;241m=\u001b[39m LogicalPath(name \u001b[38;5;129;01mor\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(local_path))\n\u001b[1;32m   1188\u001b[0m digest \u001b[38;5;241m=\u001b[39m md5_file_b64(local_path)\n",
      "\u001b[0;31mValueError\u001b[0m: Path is not a file: ./models/fasterrcnn_resnet50_fpn_kitti.pth"
     ]
    }
   ],
   "source": [
    "# training for 5 epochs\n",
    "import math\n",
    "import sys\n",
    "import time\n",
    "import utils\n",
    "\n",
    "scaler = None  # Define the \"scaler\" variable\n",
    "\n",
    "model_save_path = './models/fasterrcnn_resnet50_fpn_kitti.pth'\n",
    "print_freq = 10\n",
    "# Training loop\n",
    "\n",
    "# Assume we have an existing setup\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    metric_logger = utils.MetricLogger(delimiter=\"  \")\n",
    "    metric_logger.add_meter(\"lr\", utils.SmoothedValue(window_size=1, fmt=\"{value:.6f}\"))\n",
    "    header = f\"Epoch: [{epoch}]\"\n",
    "    start_time = time.time()\n",
    "\n",
    "    lr_scheduler = None\n",
    "    if epoch == 0:\n",
    "        warmup_factor = 1.0 / 1000\n",
    "        warmup_iters = min(1000, len(data_loader) - 1)\n",
    "\n",
    "        lr_scheduler = torch.optim.lr_scheduler.LinearLR(\n",
    "            optimizer, start_factor=warmup_factor, total_iters=warmup_iters\n",
    "        )\n",
    "\n",
    "    for images, targets in metric_logger.log_every(data_loader, print_freq, header):\n",
    "        images = list(image.to(device) for image in images)\n",
    "        targets = [{k: v.to(device) if isinstance(v, torch.Tensor) else v for k, v in t.items()} for t in targets]\n",
    "\n",
    "        \n",
    "        with torch.cuda.amp.autocast(enabled=scaler is not None):\n",
    "            loss_dict = model(images, targets)\n",
    "            losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "        # reduce losses over all GPUs for logging purposes\n",
    "        loss_dict_reduced = utils.reduce_dict(loss_dict)\n",
    "        losses_reduced = sum(loss for loss in loss_dict_reduced.values())\n",
    "\n",
    "        loss_value = losses_reduced.item()\n",
    "\n",
    "        if not math.isfinite(loss_value):\n",
    "            print(f\"Loss is {loss_value}, stopping training\")\n",
    "            print(loss_dict_reduced)\n",
    "            sys.exit(1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if lr_scheduler is not None:\n",
    "            lr_scheduler.step()\n",
    "\n",
    "        # Log metrics to WandB\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch,\n",
    "            \"loss\": loss_value,\n",
    "            \"learning_rate\": optimizer.param_groups[0][\"lr\"]\n",
    "        })\n",
    "        metric_logger.update(loss=losses_reduced, **loss_dict_reduced)\n",
    "        metric_logger.update(lr=optimizer.param_groups[0][\"lr\"])\n",
    "\n",
    "    # After each epoch\n",
    "    lr_scheduler.step()\n",
    "\n",
    "\n",
    "\n",
    "# wandb.log_artifact(model)\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "\n",
    "# model.to_onnx()\n",
    "# wandb.save(\"model.onnx\")\n",
    "\n",
    "\n",
    "# Finish WandB run\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

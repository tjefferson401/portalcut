{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic python and ML Libraries\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# for ignoring warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# We will be reading images using OpenCV\n",
    "import cv2\n",
    "\n",
    "# matplotlib for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# torchvision libraries\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms as torchtrans\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "\n",
    "# helper libraries\n",
    "from engine import train_one_epoch, evaluate\n",
    "import utils\n",
    "import transforms as T\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.models.detection as detection\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models.detection.faster_rcnn import FasterRCNN_ResNet50_FPN_Weights\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "\n",
    "# Send train=True for training transforms and False for val/test transforms\n",
    "def get_transform():\n",
    "    transform = [transforms.ToTensor()]\n",
    "    return transforms.Compose(transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial dataset size: 7481\n",
      "Training set size: 5984\n",
      "Validation set size: 748\n",
      "Testing set size: 749\n"
     ]
    }
   ],
   "source": [
    "from datasets import KittiTorch\n",
    "\n",
    "# Assuming KittiTorch and utils are defined/imported correctly\n",
    "dataset = KittiTorch(root='../data', download=True, transform=get_transform())\n",
    "\n",
    "# Print initial dataset size\n",
    "print(\"Initial dataset size:\", len(dataset))\n",
    "\n",
    "# Seed and random permutation\n",
    "torch.manual_seed(1)\n",
    "indices = torch.randperm(len(dataset)).tolist()\n",
    "\n",
    "# Calculate split sizes\n",
    "train_split = 0.8\n",
    "val_split = 0.1  # 10% for validation\n",
    "test_split = 0.1  # 10% for test\n",
    "\n",
    "# Calculate indices for splits\n",
    "train_size = int(len(dataset) * train_split)\n",
    "val_size = int(len(dataset) * val_split)\n",
    "test_size = len(dataset) - train_size - val_size  # To ensure full coverage\n",
    "\n",
    "# Split indices\n",
    "train_indices = indices[:train_size]\n",
    "val_indices = indices[train_size:train_size + val_size]\n",
    "test_indices = indices[train_size + val_size:]\n",
    "\n",
    "# Create dataset subsets\n",
    "dataset_train = torch.utils.data.Subset(dataset, train_indices)\n",
    "dataset_val = torch.utils.data.Subset(dataset, val_indices)\n",
    "dataset_test = torch.utils.data.Subset(dataset, test_indices)\n",
    "\n",
    "# Define batch size\n",
    "batch_size = 4\n",
    "\n",
    "# Data loaders\n",
    "data_loader_train = torch.utils.data.DataLoader(\n",
    "    dataset_train,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    collate_fn=utils.collate_fn,\n",
    ")\n",
    "\n",
    "data_loader_val = torch.utils.data.DataLoader(\n",
    "    dataset_val,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    collate_fn=utils.collate_fn,\n",
    ")\n",
    "\n",
    "data_loader_test = torch.utils.data.DataLoader(\n",
    "    dataset_test,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    collate_fn=utils.collate_fn,\n",
    ")\n",
    "\n",
    "# Print sizes of datasets to confirm splits\n",
    "print(\"Training set size:\", len(dataset_train))\n",
    "print(\"Validation set size:\", len(dataset_val))\n",
    "print(\"Testing set size:\", len(dataset_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs available: 1\n",
      "GPU 0: NVIDIA GeForce RTX 3070\n",
      "  - 0.00 GB\n",
      "  - Memory Cached: 0.00 GB\n",
      "  - Memory Total: 7.78 GB\n",
      "  - Compute Capability: (8, 6)\n",
      "  - Multiprocessors: 46\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "torch.cuda.empty_cache()\n",
    "if torch.cuda.is_available():\n",
    "    gpu_count = torch.cuda.device_count()\n",
    "    print(f\"Number of GPUs available: {gpu_count}\")\n",
    "    \n",
    "    for i in range(gpu_count):\n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "        print(f\"  - {torch.cuda.memory_allocated(i) / 1024**3:.2f} GB\")\n",
    "        print(f\"  - Memory Cached: {torch.cuda.memory_reserved(i) / 1024**3:.2f} GB\")\n",
    "        print(f\"  - Memory Total: {torch.cuda.get_device_properties(i).total_memory / 1024**3:.2f} GB\")\n",
    "        print(f\"  - Compute Capability: {torch.cuda.get_device_capability(i)}\")\n",
    "        print(f\"  - Multiprocessors: {torch.cuda.get_device_properties(i).multi_processor_count}\")\n",
    "else:\n",
    "    print(\"No GPU is available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_object_detection_model(num_classes):\n",
    "  model = torchvision.models.detection.fasterrcnn_resnet50_fpn_v2(pretrained=True)\n",
    "  # get number of input features for the classifier\n",
    "  in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "  # replace the pre-trained head with a new one\n",
    "  model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "\n",
    "#   for param in model.backbone.parameters():\n",
    "#         param.requires_grad = False\n",
    "        \n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_object_detection_model(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0667, 0.0627, 0.0980,  ..., 0.1451, 0.1373, 0.1412],\n",
      "         [0.0667, 0.0549, 0.0941,  ..., 0.1451, 0.1373, 0.1373],\n",
      "         [0.0667, 0.0706, 0.0706,  ..., 0.1333, 0.1255, 0.1176],\n",
      "         ...,\n",
      "         [0.0745, 0.0667, 0.0627,  ..., 0.0941, 0.0784, 0.0784],\n",
      "         [0.0471, 0.0471, 0.0549,  ..., 0.0784, 0.0824, 0.0824],\n",
      "         [0.0510, 0.0549, 0.0549,  ..., 0.0863, 0.0863, 0.0784]],\n",
      "\n",
      "        [[0.0863, 0.0941, 0.1137,  ..., 0.1137, 0.0941, 0.0667],\n",
      "         [0.0745, 0.0902, 0.1098,  ..., 0.1137, 0.0980, 0.0706],\n",
      "         [0.0627, 0.0627, 0.0824,  ..., 0.1137, 0.0902, 0.0667],\n",
      "         ...,\n",
      "         [0.0902, 0.0863, 0.0863,  ..., 0.0980, 0.1020, 0.1059],\n",
      "         [0.0824, 0.0745, 0.0706,  ..., 0.0980, 0.0980, 0.1059],\n",
      "         [0.0784, 0.0706, 0.0667,  ..., 0.1176, 0.1137, 0.1176]],\n",
      "\n",
      "        [[0.0706, 0.1098, 0.1294,  ..., 0.0902, 0.0824, 0.0588],\n",
      "         [0.0627, 0.0784, 0.0941,  ..., 0.0980, 0.0824, 0.0549],\n",
      "         [0.0627, 0.0745, 0.0824,  ..., 0.1059, 0.0863, 0.0549],\n",
      "         ...,\n",
      "         [0.1098, 0.1098, 0.1098,  ..., 0.1255, 0.1255, 0.1216],\n",
      "         [0.1098, 0.0980, 0.0941,  ..., 0.1294, 0.1255, 0.1176],\n",
      "         [0.0902, 0.0706, 0.0745,  ..., 0.1451, 0.1490, 0.1373]]])\n",
      "<class 'dict'>\n",
      "{'boxes': tensor([[712.4000, 143.0000, 810.7300, 307.9200]]),\n",
      " 'labels': tensor([4])}\n",
      "data loader part\n",
      "4\n",
      "torch.Size([3, 375, 1242])\n",
      "<class 'tuple'>\n",
      "({'boxes': tensor([[   0.0000,  230.1300,  293.5500,  374.0000],\n",
      "        [1051.3800,  218.5000, 1241.0000,  374.0000],\n",
      "        [ 756.9000,  202.2700, 1114.2200,  374.0000],\n",
      "        [ 459.1200,  189.1100,  552.1300,  264.0200],\n",
      "        [ 514.9100,  174.0800,  584.2200,  240.8500],\n",
      "        [ 557.8000,  178.8400,  612.8000,  228.5600],\n",
      "        [ 621.6100,  185.6900,  663.6600,  212.3000],\n",
      "        [ 664.7700,  181.2700,  711.6900,  202.1500]]),\n",
      "  'labels': tensor([1, 1, 1, 1, 1, 1, 1, 9])},\n",
      " {'boxes': tensor([[ 688.2700,  176.8200,  792.7700,  252.6600],\n",
      "        [1015.6300,  157.6500, 1241.0000,  279.3600],\n",
      "        [ 931.4400,  127.3800, 1241.0000,  245.0000],\n",
      "        [ 304.5400,  213.2900,  396.4600,  259.6900],\n",
      "        [ 354.6800,  182.6400,  448.4000,  244.3500],\n",
      "        [  33.6700,  204.0300,  293.8700,  335.8400],\n",
      "        [ 831.6100,  156.9700, 1024.3000,  223.4300],\n",
      "        [ 449.5900,  181.5200,  502.7800,  218.0800],\n",
      "        [ 504.3900,  170.1800,  664.4600,  209.9300],\n",
      "        [ 713.3300,  163.0700,  787.3700,  175.6500]]),\n",
      "  'labels': tensor([1, 1, 1, 8, 1, 1, 1, 1, 9, 9])},\n",
      " {'boxes': tensor([[168.2700, 197.8300, 248.9500, 232.6100],\n",
      "        [103.5600, 195.1300, 191.9700, 232.1100],\n",
      "        [  0.0000, 202.0100,  78.4000, 256.9900],\n",
      "        [533.0500, 161.9400, 560.7100, 189.6000]]),\n",
      "  'labels': tensor([1, 1, 1, 9])},\n",
      " {'boxes': tensor([[   0.0000,  224.1200,  114.2500,  374.0000],\n",
      "        [1104.3400,  150.4700, 1241.0000,  297.0100],\n",
      "        [ 164.2100,  198.1800,  376.2500,  302.2100],\n",
      "        [ 814.4400,  183.3600, 1214.8900,  374.0000],\n",
      "        [ 733.0700,  177.2400,  891.1000,  287.1900],\n",
      "        [ 333.3700,  190.8000,  435.7800,  257.6300],\n",
      "        [ 687.3000,  180.7700,  764.5800,  232.9900],\n",
      "        [ 429.2100,  186.1000,  498.9300,  229.1300],\n",
      "        [ 667.4500,  181.6400,  728.6300,  222.8700],\n",
      "        [ 495.9500,  180.8200,  531.1800,  208.7000],\n",
      "        [ 652.3700,  178.4500,  694.5700,  210.1800],\n",
      "        [ 550.9200,  174.8700,  595.8500,  191.6800],\n",
      "        [ 671.2800,  151.4200,  713.6200,  172.4100],\n",
      "        [   0.0000,  186.3500,  101.8500,  222.2200],\n",
      "        [ 283.1500,  180.5300,  358.4800,  197.6400]]),\n",
      "  'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 9, 9, 9])})\n"
     ]
    }
   ],
   "source": [
    "import pprint as pp\n",
    "\n",
    "image, target = dataset[0]\n",
    "print(image)\n",
    "print(type(target))\n",
    "pp.pprint(target)\n",
    "\n",
    "\n",
    "print(\"data loader part\")\n",
    "for images, targets in data_loader_train:\n",
    "    print(len(images))\n",
    "    print(images[0].shape)\n",
    "    print(type(targets))\n",
    "    pp.pprint(targets)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Define device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "lr = 10e-3\n",
    "\n",
    "# Define the list of classes\n",
    "class_list = ['Background', 'Car', 'Van', 'Truck', 'Pedestrian', 'Person_sitting', 'Cyclist', 'Tram', 'Misc', 'DontCare']\n",
    "num_classes = len(class_list)  # one class (class 0) is dedicated to the \"background\"\n",
    "\n",
    "# Assume get_object_detection_model is defined and returns a model instance\n",
    "model = get_object_detection_model(num_classes)\n",
    "\n",
    "# Move model to the right device\n",
    "model.to(device)\n",
    "\n",
    "# Construct an optimizer (using Adam here)\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = optim.Adam(params, lr=lr)  # Set a learning rate, modify as needed\n",
    "\n",
    "# Optionally, you can set other parameters like betas and eps\n",
    "# optimizer = optim.Adam(params, lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "# Login to WandB (only needed if you haven't configured automatic login)\n",
    "wandb.login()\n",
    "\n",
    "num_epochs = 5\n",
    "\n",
    "# Initialize a new WandB run\n",
    "wandb.init(project=\"portalcut\",\n",
    "            entity='231n-augmentation', \n",
    "            notes=\"2024-05-30-kitti-test1-fasterrcnn_resnet50_fpn_v2_scratch_50ep_v2\",\n",
    "            \n",
    "            config={\n",
    "                \"learning_rate\": lr,\n",
    "                \"epochs\": num_epochs,\n",
    "                \"batch_size\": batch_size,\n",
    "                \"optimizer\": \"Adam\",\n",
    "            })\n",
    "\n",
    "\n",
    "config = wandb.config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training for 5 epochs\n",
    "import math\n",
    "import sys\n",
    "import time\n",
    "import utils\n",
    "\n",
    "data_loader = data_loader_train\n",
    "\n",
    "scaler = None  # Define the \"scaler\" variable\n",
    "\n",
    "model_save_path = './models/2024-05-30-kitti-test1-fasterrcnn_resnet50_fpn_v2_scratch_50epv2.pth'\n",
    "print_freq = 10\n",
    "# Training loop\n",
    "\n",
    "# Assume we have an existing setup\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    metric_logger = utils.MetricLogger(delimiter=\"  \")\n",
    "    metric_logger.add_meter(\"lr\", utils.SmoothedValue(window_size=1, fmt=\"{value:.6f}\"))\n",
    "    header = f\"Epoch: [{epoch}]\"\n",
    "    start_time = time.time()\n",
    "\n",
    "    lr_scheduler = None\n",
    "    if epoch == 0:\n",
    "        warmup_factor = 1.0 / 1000\n",
    "        warmup_iters = min(1000, len(data_loader) - 1)\n",
    "\n",
    "        lr_scheduler = torch.optim.lr_scheduler.LinearLR(\n",
    "            optimizer, start_factor=warmup_factor, total_iters=warmup_iters\n",
    "        )\n",
    "\n",
    "    for images, targets in metric_logger.log_every(data_loader, print_freq, header):\n",
    "        images = list(image.to(device) for image in images)\n",
    "        targets = [{k: v.to(device) if isinstance(v, torch.Tensor) else v for k, v in t.items()} for t in targets]\n",
    "\n",
    "        \n",
    "        with torch.cuda.amp.autocast(enabled=scaler is not None):\n",
    "            loss_dict = model(images, targets)\n",
    "            losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "        # reduce losses over all GPUs for logging purposes\n",
    "        loss_dict_reduced = utils.reduce_dict(loss_dict)\n",
    "        losses_reduced = sum(loss for loss in loss_dict_reduced.values())\n",
    "\n",
    "        loss_value = losses_reduced.item()\n",
    "\n",
    "        if not math.isfinite(loss_value):\n",
    "            print(f\"Loss is {loss_value}, stopping training\")\n",
    "            print(loss_dict_reduced)\n",
    "            sys.exit(1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if lr_scheduler is not None:\n",
    "            lr_scheduler.step()\n",
    "\n",
    "        # Log metrics to WandB\n",
    "        wandb.log({\n",
    "            **loss_dict_reduced,\n",
    "            \"epoch\": epoch,\n",
    "            \"loss\": loss_value,\n",
    "            \"learning_rate\": optimizer.param_groups[0][\"lr\"]\n",
    "        })\n",
    "        metric_logger.update(loss=losses_reduced, **loss_dict_reduced)\n",
    "        metric_logger.update(lr=optimizer.param_groups[0][\"lr\"])\n",
    "        print(loss_dict)\n",
    "        print(loss_dict_reduced)\n",
    "\n",
    "    # After each epoch\n",
    "    # lr_scheduler.step()\n",
    "\n",
    "\n",
    "\n",
    "# wandb.log_artifact(model)\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "\n",
    "# model.to_onnx()\n",
    "# wandb.save(\"model.onnx\")\n",
    "\n",
    "\n",
    "# Finish WandB run\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    gpu_count = torch.cuda.device_count()\n",
    "    print(f\"Number of GPUs available: {gpu_count}\")\n",
    "    \n",
    "    for i in range(gpu_count):\n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "        print(f\"  - {torch.cuda.memory_allocated(i) / 1024**3:.2f} GB\")\n",
    "        print(f\"  - Memory Cached: {torch.cuda.memory_reserved(i) / 1024**3:.2f} GB\")\n",
    "        print(f\"  - Memory Total: {torch.cuda.get_device_properties(i).total_memory / 1024**3:.2f} GB\")\n",
    "        print(f\"  - Compute Capability: {torch.cuda.get_device_capability(i)}\")\n",
    "        print(f\"  - Multiprocessors: {torch.cuda.get_device_properties(i).multi_processor_count}\")\n",
    "else:\n",
    "    print(\"No GPU is available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the code that saves up the model from the internet and tests it\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = dataset_test[5][0]\n",
    "# Load the model\n",
    "model.load_state_dict(torch.load(model_save_path))\n",
    "\n",
    "# Ensure your model is on the GPU\n",
    "model = model.to('cuda')\n",
    "\n",
    "# Move the input tensor to the GPU\n",
    "input_tensor = image.unsqueeze(0).to('cuda')\n",
    "\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# Disable gradient computation during inference\n",
    "with torch.no_grad():\n",
    "    predictions = model(input_tensor)\n",
    "\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def visualize_image_with_boxes(image, boxes, labels, label_names):\n",
    "    # Convert tensor image to numpy array\n",
    "    image = image.cpu().numpy().transpose((1, 2, 0))\n",
    "    # Scale the image's pixel values to [0, 255]\n",
    "    image = cv2.normalize(image, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F).astype(np.uint8)\n",
    "    # Convert the image to CPU and NumPy format for plotting\n",
    "\n",
    "\n",
    "    # Define colors for different classes\n",
    "    colors = {\n",
    "        'Car': (255, 0, 0), 'Van': (0, 255, 0), 'Truck': (0, 0, 255),\n",
    "        'Pedestrian': (255, 255, 0), 'Person_sitting': (255, 0, 255), 'Cyclist': (0, 255, 255),\n",
    "        'Tram': (127, 127, 255), 'Misc': (255, 127, 127), \"Don'tCare\": (127, 127, 127)\n",
    "    }\n",
    "\n",
    "    # Draw boxes and labels\n",
    "    for box, label in zip(boxes, labels):\n",
    "        box = box.cpu().numpy().astype(int)\n",
    "        label = int(label.cpu())\n",
    "        box = box.astype(int)\n",
    "        print(label)\n",
    "        label_text = label_names[label]\n",
    "        color = colors.get(label_text, (255, 255, 255))\n",
    "\n",
    "        # Draw rectangle\n",
    "        cv2.rectangle(image, (box[0], box[1]), (box[2], box[3]), color, 2)\n",
    "\n",
    "        # Put label\n",
    "        cv2.putText(image, label_text, (box[0], box[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "    # Display the image\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Define label names based on your dataset specifics\n",
    "label_names = ['Background', 'Car', 'Van', 'Truck', 'Pedestrian', 'Person_sitting', 'Cyclist', 'Tram', 'Misc', 'DontCare']\n",
    "\n",
    "# Sample call to the function\n",
    "\n",
    "target = predictions[0]\n",
    "# image = dataset[0][0]\n",
    "plt.imshow(image.permute(1, 2, 0))\n",
    "# This assumes `image` is a tensor from the dataset, `boxes` is a tensor of bounding boxes, and `labels` is a tensor of label indices\n",
    "visualize_image_with_boxes(image, target['boxes'], target['labels'], label_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torchvision.ops import box_iou\n",
    "from collections import defaultdict\n",
    "\n",
    "# Load the model\n",
    "model.load_state_dict(torch.load(model_save_path))\n",
    "model = model.to('cuda')\n",
    "model.eval()\n",
    "\n",
    "# Define label names based on your dataset specifics\n",
    "label_names = ['Background', 'Car', 'Van', 'Truck', 'Pedestrian', 'Person_sitting', 'Cyclist', 'Tram', 'Misc', 'DontCare']\n",
    "\n",
    "def compute_iou(boxes1, boxes2):\n",
    "    if boxes1.numel() == 0 or boxes2.numel() == 0:\n",
    "        return torch.tensor([]).to(boxes1.device)\n",
    "    boxes1 = boxes1.to('cuda')\n",
    "    boxes2 = boxes2.to('cuda')\n",
    "    ious = box_iou(boxes1, boxes2)\n",
    "    return ious\n",
    "\n",
    "def evaluate_model(model, dataset, label_names, iou_threshold=0.5):\n",
    "    all_true_boxes = []\n",
    "    all_pred_boxes = []\n",
    "    all_true_labels = []\n",
    "    all_pred_labels = []\n",
    "\n",
    "    for idx in range(len(dataset)):\n",
    "        image, target = dataset[idx]\n",
    "        input_tensor = image.unsqueeze(0).to('cuda')\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            predictions = model(input_tensor)[0]\n",
    "        \n",
    "        true_boxes = target['boxes'].to('cuda')\n",
    "        true_labels = target['labels'].to('cuda')\n",
    "        pred_boxes = predictions['boxes'].to('cuda')\n",
    "        pred_labels = predictions['labels'].to('cuda')\n",
    "\n",
    "        all_true_boxes.append(true_boxes)\n",
    "        all_pred_boxes.append(pred_boxes)\n",
    "        all_true_labels.append(true_labels)\n",
    "        all_pred_labels.append(pred_labels)\n",
    "\n",
    "    iou_scores = []\n",
    "    for true_boxes, pred_boxes in zip(all_true_boxes, all_pred_boxes):\n",
    "        iou_scores.append(compute_iou(true_boxes, pred_boxes))\n",
    "\n",
    "    mean_iou = torch.mean(torch.stack([torch.mean(iou) for iou in iou_scores if iou.numel() > 0]))\n",
    "    print(f\"Mean IoU: {mean_iou:.4f}\")\n",
    "\n",
    "    # Compute mAP (mean Average Precision)\n",
    "    aps = []\n",
    "    for i, label_name in enumerate(label_names):\n",
    "        if label_name == \"Background\":\n",
    "            continue\n",
    "        \n",
    "        true_positives = []\n",
    "        false_positives = []\n",
    "        num_gt = 0\n",
    "\n",
    "        for true_boxes, true_labels, pred_boxes, pred_labels in zip(all_true_boxes, all_true_labels, all_pred_boxes, all_pred_labels):\n",
    "            gt_boxes = true_boxes[true_labels == i]\n",
    "            pred_boxes = pred_boxes[pred_labels == i]\n",
    "            num_gt += len(gt_boxes)\n",
    "\n",
    "            if len(pred_boxes) == 0:\n",
    "                continue\n",
    "            \n",
    "            ious = compute_iou(gt_boxes, pred_boxes)\n",
    "            if ious.numel() == 0:\n",
    "                continue\n",
    "            true_positive = ious.max(dim=0)[0] > iou_threshold\n",
    "            false_positive = ~true_positive\n",
    "\n",
    "            true_positives.extend(true_positive.cpu().numpy())\n",
    "            false_positives.extend(false_positive.cpu().numpy())\n",
    "        \n",
    "        tp_cumsum = np.cumsum(true_positives)\n",
    "        fp_cumsum = np.cumsum(false_positives)\n",
    "        precisions = tp_cumsum / (tp_cumsum + fp_cumsum + 1e-6)\n",
    "        recalls = tp_cumsum / (num_gt + 1e-6)\n",
    "\n",
    "        ap = np.trapz(precisions, recalls)\n",
    "        aps.append(ap)\n",
    "\n",
    "        print(f\"AP for {label_name}: {ap:.4f}\")\n",
    "\n",
    "    mAP = np.mean(aps)\n",
    "    print(f\"Mean Average Precision (mAP): {mAP:.4f}\")\n",
    "\n",
    "# Example usage\n",
    "evaluate_model(model, dataset_test, label_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(model, dataset, label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
